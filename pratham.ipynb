{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport cv2\n%matplotlib inline\nimages=os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images\")\na=os.listdir(images)\na.sort()\ntest_images=a[:1698]\ntrain_images=a[1698:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/train.csv\"))\ntrain_csv=train_csv.sort_values(by=['name'])\nsubmission=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/submission.csv\"))\n# codes={}\n# train_csv[\"classname\"].unique()\n# for i in range(len(df[\"class\"].unique())):\n#     codes[df[\"class\"].unique()[i]]=train_csv[\"classname\"].unique()[i]\n# print(codes)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=train_csv\nbbox=[]\nx=[]\ny=[]\nw=[]\nh=[]\nfor i in range(len(train_csv)):\n    arr=[]\n    for j in df.iloc[i][[\"x1\",'x2','y1','y2']]:\n        arr.append(j)\n    arr[2]=arr[2]-arr[0]\n    arr[3]=arr[3]-arr[1]\n    bbox.append(arr)\n    x.append(arr[0])\n    y.append(arr[1])\n    w.append(arr[2])\n    h.append(arr[3])\ndf[\"bbox\"]=bbox\ndf[\"x\"]=x\ndf[\"y\"]=y\ndf[\"w\"]=w\ndf[\"h\"]=h\ndf.classname = pd.Categorical(df.classname)\ndf[\"class\"] = df.classname.cat.codes\ndf.drop(columns=[\"x1\",\"x2\",'y1','y2'],inplace=True)\ndf.columns=[\"image_id\",\"classname\",\"bbox\",\"x\",\"y\",\"w\",\"h\",\"class\"]\nsubmission[\"image_id\"]=submission[\"name\"]\ndf.drop(columns=\"classname\",inplace=True)\ndf[[\"x\",\"y\",\"w\",\"h\"]]=df[[\"x\",\"y\",\"w\",\"h\"]].astype(float)\ndf.bbox=df.bbox.astype(str)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# codes={}\n# train_csv[\"classname\"].unique()\n# for i in range(len(df[\"class\"].unique())):\n#     codes[df[\"class\"].unique()[i]]=train_csv[\"classname\"].unique()[i]\n# print(codes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_boxes(id):\n    boxes=[]\n    for i in df[df[\"image_id\"]==str(id)][\"bbox\"]:\n        boxes.append(list(map(float,i[1:-1].split(\", \"))))\n    return boxes\nprint(get_boxes('1806.jpg'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\nimport matplotlib.patches as patches\nimage=\"1799.jpg\"\n\nimg=plt.imread(os.path.join(images,image))\n\nfig,ax = plt.subplots(1)\nax.imshow(img)\nboxes=get_boxes(image)\nfor box in boxes:\n    rect = patches.Rectangle((box[0],box[1]),box[2],box[3],linewidth=2,edgecolor='r',facecolor='none')\n    ax.add_patch(rect)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boxes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport os\nimport re\nimport torch\nimport torchvision\nfrom torchvision import transforms \nimport numpy as np\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torchvision.models.detection import FasterRCNN\nfrom torchvision.models.detection.rpn import AnchorGenerator\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SequentialSampler\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trans = transforms.Compose([transforms.ToTensor()])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class WheatDataset(Dataset):\n\n    def __init__(self, dataframe, image_dir, transforms=None,train=True):\n        super().__init__()\n\n        self.image_ids = dataframe['image_id'].unique()\n        self.df = dataframe\n        self.image_dir = image_dir\n        self.transforms = transforms\n        self.train=train\n\n    def __len__(self) -> int:\n        return self.image_ids.shape[0]\n\n    def __getitem__(self, index: int):\n\n        image_id = self.image_ids[index]\n        image = cv2.imread(f'{self.image_dir}/{image_id}', cv2.IMREAD_COLOR)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n        image /= 255.0\n        if self.transforms is not None:  #Apply transformation\n            image = self.transforms(image)\n        if(self.train==False):  # For test data\n            return image, image_id\n        #Else for train and validation data\n        records = self.df[self.df['image_id'] == image_id]   \n        boxes = records[['x', 'y', 'w', 'h']].values\n        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        \n        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n        area = torch.as_tensor(area, dtype=torch.float32)\n\n        # there is only one class\n        labels = torch.as_tensor(list(records[\"class\"]), dtype=torch.int64)\n        \n        # suppose all instances are not crowd\n        iscrowd = torch.zeros((records.shape[0],), dtype=torch.int64)\n        \n        target = {}\n        target['boxes'] = boxes\n        target['labels'] = labels\n        target['image_id'] = torch.tensor([index])\n        target['area'] = area\n        target['iscrowd'] = iscrowd\n\n        return image, target,image_id  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Averager:      ##Return the average loss \n    def __init__(self):\n        self.current_total = 0.0\n        self.iterations = 0.0\n\n    def send(self, value):\n        self.current_total += value\n        self.iterations += 1\n\n    @property\n    def value(self):\n        if self.iterations == 0:\n            return 0\n        else:\n            return 1.0 * self.current_total / self.iterations\n\n    def reset(self):\n        self.current_total = 0.0\n        self.iterations = 0.0\n        \n        \ndef collate_fn(batch):\n    return tuple(zip(*batch))\n\ntrain_dataset = WheatDataset(df, images, trans,True)\ntest_dataset = WheatDataset(submission, images, trans,False)\n\n\n\n# split the dataset in train and test set\nindices = torch.randperm(len(train_dataset)).tolist()\n\ntrain_data_loader = DataLoader(\n    train_dataset,\n    batch_size=4,\n    shuffle=False,\n    num_workers=4,\n    collate_fn=collate_fn\n)\ntest_data_loader = DataLoader(\n    test_dataset,\n    batch_size=2,\n    shuffle=False,\n    num_workers=4,\n    collate_fn=collate_fn\n)\n\n#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# img,image_ids= next(iter(test_data_loader))\n# print(img[1].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# images, targets, image_ids = next(iter(train_data_loader))\n# images = list(image.to(device) for image in images)\n# targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n# boxes = targets[3]['boxes'].cpu().numpy().astype(np.int32)\n# sample = images[3].permute(1,2,0).cpu().numpy()\n\n# fig, ax = plt.subplots(1, 1, figsize=(16, 8))\n\n# for box in boxes:\n#     cv2.rectangle(sample,\n#                   (box[0], box[1]),\n#                   (box[2], box[3]),\n#                   (220, 0, 0), 3)\n    \n# ax.set_axis_off()\n# ax.imshow(sample)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True, pretrained_backbone=False)\nnum_classes = 21  # 1 class (wheat) + background\n\nin_features = model.roi_heads.box_predictor.cls_score.in_features\n\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pass_this=('1861.jpg', '1862.jpg', '1864.jpg', '1865.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nmodel.train()\nmodel.to(device)\nparams = [p for p in model.parameters() if p.requires_grad]\noptimizer = torch.optim.SGD(params, lr=0.01, momentum=0.9, weight_decay=0.00001)\nlr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.5)\n#lr_scheduler = None\n\nnum_epochs = 5\n\nloss_hist = Averager()\nitr = 1\n\nfor epoch in range(num_epochs):\n    loss_hist.reset()\n    \n    for images, targets, image_ids in train_data_loader:\n        if image_ids==pass_this:\n            continue\n        images = list(image.to(device) for image in images)\n#         if itr==1:    \n#             print(\"images\")\n#             print(images)\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n#         if itr==1:\n#             print(\"targets\")\n#             print(targets)\n        loss_dict = model(images, targets)   ##Return the loss\n#         print(\"loss dict\")\n#         print(loss_dict)\n        losses = sum(loss for loss in loss_dict.values())\n        x=float(losses)\n#         print(f\"losses {losses.item()} and {loss_hist.value}\")\n        if math.isnan(x):\n            print(images,targets)\n            break\n        loss_value = losses.item()\n#         print(\"loss_value \",loss_value)\n        loss_hist.send(loss_value)  #Average out the loss\n\n    \n        optimizer.zero_grad()\n        losses.backward()\n        optimizer.step()\n\n        if itr % 100 == 0:\n            print(f\"Iteration #{itr} loss: {loss_value} losss: {losses}\")\n\n        itr += 1\n#         if itr==2:\n#             break\n    # update the learning rate\n    if lr_scheduler is not None:\n        lr_scheduler.step()\n\n    print(f\"Epoch #{epoch} loss: {loss_hist.value} losss:{loss_value}\")\n#     break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def format_prediction_string(boxes, scores,labels): ## Define the formate for storing prediction results\n#     pred_strings = []\n#     for j in zip(scores, boxes,labels):\n# #         print(j)\n#         pred_strings.append(\"{0} {1} {2} {3} {4}\".format(j[1][0], j[1][1], j[1][2], j[1][3],j[2]))\n\n#     return \" \".join(pred_strings)\n    box=[]\n    lab=[]\n    for j in zip(scores,boxes,labels):\n        box.append([j[1][0], j[1][1], j[1][2], j[1][3]])\n        lab.append(j[2])\n    return box,lab","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Lets make the prediction\nresults=[]\nmodel.eval()\ndetection_threshold = 0.40\n\nfor images, image_ids in test_data_loader:    \n\n    images = list(image.to(device) for image in images)\n    outputs = model(images)\n\n    for i, image in enumerate(images):\n\n        boxes = outputs[i]['boxes'].data.cpu().numpy()    ##Formate of the output's box is [Xmin,Ymin,Xmax,Ymax]\n        scores = outputs[i]['scores'].data.cpu().numpy()\n        labels = outputs[i]['labels'].data.cpu().numpy()\n        \n        boxes = boxes[scores >= detection_threshold].astype(np.int32) #Compare the score of output with the threshold and\n        labels = labels[scores >= detection_threshold].astype(np.int32)\n        scores = scores[scores >= detection_threshold]                 \n\n        image_id = image_ids[i]\n        \n        boxes[:, 2] = boxes[:, 2] - boxes[:, 0]         \n        boxes[:, 3] = boxes[:, 3] - boxes[:, 1]         #Convert the box formate to [Xmin,Ymin,W,H]\n        \n        \n        b,l=format_prediction_string(boxes, scores,labels)    \n        result = {                                     #Store the image id and boxes and scores in result dict.\n            'image_id': image_id,\n#             'PredictionString': format_prediction_string(boxes, scores,labels)\n            'boxes':b,\n            'labels':l\n        }\n\n        \n        results.append(result)              #Append the result dict to Results list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/train.csv\"))\ntrain_csv=train_csv.sort_values(by=['name'])\nsubmission=pd.read_csv(os.path.join(\"/kaggle/input/face-mask-detection-dataset/submission.csv\"))\ncodes={}\ntrain_csv[\"classname\"].unique()\nfor i in range(len(df[\"class\"].unique())):\n    codes[df[\"class\"].unique()[i]]=train_csv[\"classname\"].unique()[i]\nprint(codes)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport cv2\n%matplotlib inline\nimages=os.path.join(\"/kaggle/input/face-mask-detection-dataset/Medical mask/Medical mask/Medical Mask/images\")\na=os.listdir(images)\na.sort()\ntest_images=a[:1698]\ntrain_images=a[1698:]\nimport matplotlib.pyplot as plt\nimport cv2\nimport matplotlib.patches as patches\nimage=\"1800.jpg\"\n\nimg=plt.imread(os.path.join(images,image))\n\nfig,ax = plt.subplots(1)\nax.imshow(img)\nboxes=get_boxes(image)\n# for i in results[0][\"boxes\"]:\n#     rect = patches.Rectangle((i[0],i[1]),i[2],i[3],linewidth=2,edgecolor='r',facecolor='none')\n#     ax.add_patch(rect)\nrect = patches.Rectangle((913,252),575,631,linewidth=2,edgecolor='r',facecolor='none')\nax.add_patch(rect)\n# rect = patches.Rectangle((328,391),156,140,linewidth=2,edgecolor='r',facecolor='none')\n# ax.add_patch(rect)\n# rect = patches.Rectangle((906,185),107,60,linewidth=2,edgecolor='r',facecolor='none')\n# ax.add_patch(rect)\n# rect = patches.Rectangle((675,203),175,225,linewidth=2,edgecolor='r',facecolor='none')\n# ax.add_patch(rect)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results[2][\"image_id\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.DataFrame(columns=['name', \"x1\",\"x2\",\"y1\",\"y2\",\"classname\"])\nfor i in range(len(results)):\n    for j in range(len(results[i][\"boxes\"])):\n        test_df=test_df.append({'name':results[i][\"image_id\"], \"x1\":results[i][\"boxes\"][j][0],\"x2\":results[i][\"boxes\"][j][1],\"y1\":results[i][\"boxes\"][j][2]+results[i][\"boxes\"][j][0],\"y2\":results[i][\"boxes\"][j][3]+results[i][\"boxes\"][j][1],\"classname\":codes[results[i][\"labels\"][j]]},ignore_index=True)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}